{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9237cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d15aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\DATA SCIENCE AND ML\\Project\\job_trend_predictor\\data\\processed\\validated\\jobs_validated_20260107_095333.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52e2c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Company', 'Experience', 'Salary', 'Location', 'Education',\n",
       "       'Star_Skills', 'Normal_Skills', 'Posted_Date', 'Last_Apply_Date',\n",
       "       'Role', 'Industry Type', 'Department', 'Employment Type',\n",
       "       'Role Category', 'Description', 'Job_URL', 'Scraped_At', 'Job_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb9a4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ['Data Scientist']\n",
      "2. ['Web Developer']\n",
      "3. ['Web Developer']\n",
      "4. ['DevOps Engineer']\n",
      "5. ['Other']\n",
      "6. ['Generative AI Engineer']\n",
      "7. ['Machine Learning Engineer']\n",
      "8. ['Machine Learning Engineer']\n",
      "9. ['Full Stack Developer']\n",
      "10. ['Ruby on Rails Developer']\n",
      "11. ['Other']\n",
      "12. ['Other']\n",
      "13. ['Python Developer']\n",
      "14. ['Software Engineer']\n",
      "15. ['Machine Learning Engineer']\n",
      "16. ['DevOps Engineer']\n",
      "17. ['Other']\n",
      "18. ['Other']\n"
     ]
    }
   ],
   "source": [
    "# updated code \n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "unique_job_list = [\n",
    "    \"Data Scientist\",\n",
    "    \"Machine Learning Engineer\",\n",
    "    \"Data Analyst\",\n",
    "    \"Business Analyst\",\n",
    "    \"AI Engineer\",\n",
    "    \"Research Associate\",\n",
    "    \"Data Engineer\",\n",
    "    \"Web Developer\",\n",
    "    \"Software Engineer\",\n",
    "    \"DevOps Engineer\",\n",
    "    \"Product Manager\",\n",
    "    \"Project Manager\",\n",
    "    \"UX Designer\",\n",
    "    \"Full Stack Developer\",\n",
    "    \"Cloud Engineer\",\n",
    "    \"DevOps Specialist\",\n",
    "    \"Database Administrator\",\n",
    "    \"Cybersecurity Analyst\",\n",
    "    \"Network Engineer\",\n",
    "    \"Systems Analyst\",\n",
    "    \"IT Support Specialist\",\n",
    "    \"Mobile App Developer\",\n",
    "    \"Front End Developer\",\n",
    "    \"Back End Developer\",\n",
    "    \"QA Engineer\",\n",
    "    \"Technical Writer\",\n",
    "    \"Scrum Master\",\n",
    "    \"Python Developer\",\n",
    "    \"Java Developer\",\n",
    "    \"Ruby on Rails Developer\",\n",
    "    \"Big Data Engineer\",\n",
    "    \"Data Architect\",\n",
    "    \"AI Researcher\",\n",
    "    \"Blockchain Developer\",\n",
    "    \"Computer Vision Engineer\",\n",
    "    \"NLP Engineer\",\n",
    "    \"Robotics Engineer\",\n",
    "    \"Game Developer\",\n",
    "    \"Embedded Systems Engineer\",\n",
    "    \"Site Reliability Engineer\",\n",
    "    \"Solutions Architect\",\n",
    "    \"IT Consultant\",\n",
    "    \"Business Intelligence Analyst\",\n",
    "    \"Generative AI Specialist\",\n",
    "    \"Generative AI Engineer\",\n",
    "    \"Technical Support Specialist\",\n",
    "    \"Customer Support Specialist\"\n",
    "]\n",
    "\n",
    "def fuzzy_matcher(job_list, x):\n",
    "    \"\"\"\n",
    "    Match job title to predefined job list using fuzzy matching.\n",
    "    \n",
    "    Args:\n",
    "        job_list: List of standardized job titles\n",
    "        x: Raw job title string to match\n",
    "        \n",
    "    Returns:\n",
    "        List containing the best matching job title(s) or [\"Other\"] if no match\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return [\"Other\"]\n",
    "    \n",
    "    if not job_list:\n",
    "        raise ValueError(\"Please provide valid list of jobs\")\n",
    "    \n",
    "    # Convert to lowercase and strip whitespace\n",
    "    x = x.lower().strip()\n",
    "    \n",
    "    # Remove metadata keywords using word boundaries\n",
    "    metadata_patterns = [\n",
    "        r'\\bhiring\\b', r'\\bimmediate\\s+joiner?\\b', r'\\bopening\\s+for\\b',\n",
    "        r'\\burgent\\b', r'\\bimmediate\\s+joining\\b', r'\\bwalk-?in\\b',\n",
    "        r'\\bfreshers?\\b', r'\\bexperienced?\\b'\n",
    "    ]\n",
    "    for pattern in metadata_patterns:\n",
    "        x = re.sub(pattern, '', x, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    # Remove location markers (before first separator)\n",
    "    x = re.split(r'\\s*[-|,@]\\s*', x)[0].strip()\n",
    "    \n",
    "    # Expand abbreviations with word boundaries for precision\n",
    "    # Order matters: longer patterns first to avoid partial replacements\n",
    "    x = re.sub(r'\\bgen\\s*ai\\b', 'generative ai', x, flags=re.IGNORECASE)\n",
    "    x = re.sub(r'\\bsre\\b', 'site reliability engineer', x, flags=re.IGNORECASE)\n",
    "    x = re.sub(r'\\bml\\b', 'machine learning', x, flags=re.IGNORECASE)\n",
    "    x = re.sub(r'\\bai\\b', 'artificial intelligence', x, flags=re.IGNORECASE)\n",
    "    x = re.sub(r'\\bfs\\b', 'full stack', x, flags=re.IGNORECASE)\n",
    "    x = re.sub(r'\\bdev\\b', 'developer', x, flags=re.IGNORECASE)\n",
    "    x = re.sub(r'\\bengg?\\b', 'engineer', x, flags=re.IGNORECASE)\n",
    "    x = re.sub(r'\\bmgr\\b', 'manager', x, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove seniority markers with word boundaries\n",
    "    seniority_patterns = [\n",
    "        r'\\bsenior\\b', r'\\bjr\\.?\\b', r'\\bsr\\.?\\b', r'\\blead\\b',\n",
    "        r'\\bprincipal\\b', r'\\bassociate\\b', r'\\bintern\\b', r'\\btrainee\\b',\n",
    "        r'\\bmid-?level\\b', r'\\bentry-?level\\b', r'\\bstaff\\b'\n",
    "    ]\n",
    "    for pattern in seniority_patterns:\n",
    "        x = re.sub(pattern, '', x, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    x = re.sub(r'\\s+', ' ', x).strip()\n",
    "    \n",
    "    # If empty after cleaning, return Other\n",
    "    if not x:\n",
    "        return [\"Other\"]\n",
    "    \n",
    "    # Calculate fuzzy match scores\n",
    "    matching_scores = {}\n",
    "    for job in job_list:\n",
    "        matching_scores[job] = fuzz.token_set_ratio(job.lower(), x)\n",
    "    \n",
    "    # Sort by score descending\n",
    "    sorted_matches = sorted(matching_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Get top score\n",
    "    top_score = sorted_matches[0][1]\n",
    "    \n",
    "    # Return matches based on score thresholds\n",
    "    if top_score >= 80:\n",
    "        # High confidence: return top match only\n",
    "        return [sorted_matches[0][0]]\n",
    "    elif top_score >= 70:\n",
    "        # Medium confidence: return top 2 if second score is within 5 points\n",
    "        top_matches = [sorted_matches[0][0]]\n",
    "        if len(sorted_matches) > 1 and sorted_matches[1][1] >= top_score - 5:\n",
    "            top_matches.append(sorted_matches[1][0])\n",
    "        return top_matches\n",
    "    else:\n",
    "        # Low confidence: return \"Other\"\n",
    "        return [\"Other\"]\n",
    "\n",
    "\n",
    "# Test cases\n",
    "print(\"1.\", fuzzy_matcher(unique_job_list, \"Machine Learning Engineer and Data Scientist\"))\n",
    "print(\"2.\", fuzzy_matcher(unique_job_list, \"Frontend developer - SE - Noida\"))\n",
    "print(\"3.\", fuzzy_matcher(unique_job_list, \"Gen Ai Developer\"))\n",
    "print(\"4.\", fuzzy_matcher(unique_job_list, \"DevOps/SRE Lead (Specialist)-Pune\"))\n",
    "print(\"5.\", fuzzy_matcher(unique_job_list, \"Gen AI/Agentic AI Engineers\"))\n",
    "print(\"6.\", fuzzy_matcher(unique_job_list, \"Gen AI Engineer\"))\n",
    "print(\"7.\", fuzzy_matcher(unique_job_list, \"Hiring Machine Learning Engineerr\"))\n",
    "print(\"8.\", fuzzy_matcher(unique_job_list, \"Immediat Hiring for Machine Learning Engineerr\"))\n",
    "print(\"9.\", fuzzy_matcher(unique_job_list, \"  Full stack Developer (React + Springboot)\"))\n",
    "print(\"10.\", fuzzy_matcher(unique_job_list, \" Opening For Ruby on rails Developer\"))\n",
    "print(\"11.\", fuzzy_matcher(unique_job_list, \" Hiring | Customer Service / Tech Support | Jaipur | 3 To 4 LPA\"))\n",
    "print(\"12.\", fuzzy_matcher(unique_job_list, \" Hiring For International Voice Process - AR Callers\"))\n",
    "print(\"13.\", fuzzy_matcher(unique_job_list, \" Python Software Developer- Bangalore (Pan India Infosys)\"))\n",
    "print(\"14.\", fuzzy_matcher(unique_job_list, \"Senior Software Engineer\"))\n",
    "print(\"15.\", fuzzy_matcher(unique_job_list, \"ML Engineer\"))\n",
    "print(\"16.\", fuzzy_matcher(unique_job_list, \"DevOps/Cloud Engineer\"))\n",
    "print(\"17.\", fuzzy_matcher(unique_job_list, \"\"))\n",
    "print(\"18.\", fuzzy_matcher(unique_job_list, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6341ca85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3316c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TItle_Cleaned\"] = df[\"Title\"].apply(lambda x: fuzzy_matcher(unique_job_list, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e77a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a025b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Company Name Cleaner:\n",
      "------------------------------------------------------------\n",
      "Input:  'Hiring for Google Inc - Urgent'              → Output: Google\n",
      "Input:  'Posted by: Amazon | Bangalore'               → Output: Unknown\n",
      "Input:  'Accenture Pvt Ltd'                           → Output: Accenture\n",
      "Input:  'Microsoft Corporation'                       → Output: Microsoft\n",
      "Input:  'Wipro'                                       → Output: Wipro\n",
      "Input:  'TCS - Immediate Joiner'                      → Output: TCS\n",
      "Input:  'Opening for Infosys Limited'                 → Output: Infosys\n",
      "Input:  'Now Hiring @ Adobe Inc.'                     → Output: Unknown\n",
      "Input:  'Flipkart - Work From Home'                   → Output: Flipkart\n",
      "Input:  'Urgent Hiring - Cognizant'                   → Output: Unknown\n",
      "Input:  'Apple Inc - Remote'                          → Output: Apple\n",
      "Input:  '  IBM Corp  '                                → Output: IBM\n",
      "Input:  'Oracle Corporation (Urgent)'                 → Output: Oracle\n",
      "Input:  ''                                            → Output: Unknown\n",
      "Input:  None                                          → Output: Unknown\n",
      "Input:  'A'                                           → Output: Unknown\n",
      "Input:  'Posted by Deloitte | Hyderabad | 5 LPA'      → Output: Deloitte\n",
      "Input:  'Cygnus Professionals'                        → Output: Cygnus Professionals\n",
      "Input:  'Centre for Computational Technologies (CCTech)' → Output: Centre for Computational Technologies (CCTech)\n",
      "Input:  'Mapmyindia Pvt. Ltd.'                        → Output: Mapmyindia .\n",
      "Input:  'Sirahu Technologies Inc'                     → Output: Sirahu Technologies\n"
     ]
    }
   ],
   "source": [
    "# updated code \n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_company_name(company: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean company name by removing hiring metadata, legal suffixes, and normalizing format.\n",
    "    \n",
    "    Args:\n",
    "        company: Raw company name string\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned company name or \"Unknown\" if invalid/empty\n",
    "    \"\"\"\n",
    "    # Handle None or non-string inputs\n",
    "    if not isinstance(company, str) or company is None or pd.isna(company):\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Strip initial whitespace\n",
    "    company = company.strip()\n",
    "    \n",
    "    if not company:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Step 1: Remove hiring/job posting prefixes (case-insensitive)\n",
    "    prefix_patterns = [\n",
    "        r'\\bHiring\\s+for\\b',\n",
    "        r'\\bImmediate\\s+Hiring\\b',\n",
    "        r'\\bPosted\\s+by:?\\b',\n",
    "        r'\\bUrgent\\s+Hiring\\b',\n",
    "        r'\\bWalk-?in\\b',\n",
    "        r'\\bOpening\\s+for\\b',\n",
    "        r'\\bNow\\s+Hiring\\b',\n",
    "        r'\\bJobs?\\s+at\\b',\n",
    "        r'\\bCareers?\\s+at\\b',\n",
    "        r'\\bHiring\\s*@\\b',\n",
    "        r'\\bJoin\\b',\n",
    "        r'\\bApply\\s+to\\b',\n",
    "        r'\\bWork\\s+at\\b'\n",
    "    ]\n",
    "    \n",
    "    for pattern in prefix_patterns:\n",
    "        company = re.sub(pattern, '', company, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    # Step 2: Split on common separators and take first part (main company name)\n",
    "    # This handles cases like \"Amazon | Bangalore\" or \"Google - Urgent\"\n",
    "    company = re.split(r'\\s*[-|:@]\\s*', company)[0].strip()\n",
    "    \n",
    "    # Step 3: Remove legal entity suffixes (case-insensitive)\n",
    "    suffix_patterns = [\n",
    "        r'\\bPvt\\.?\\s*Ltd\\.?\\b',\n",
    "        r'\\bPrivate\\s+Limited\\b',\n",
    "        r'\\bLimited\\b',\n",
    "        r'\\bLtd\\.?\\b',\n",
    "        r'\\bLLP\\b',\n",
    "        r'\\bInc\\.?\\b',\n",
    "        r'\\bCorporation\\b',\n",
    "        r'\\bCorp\\.?\\b',\n",
    "        r'\\bCompany\\b',\n",
    "        r'\\bCo\\.?\\b(?!\\w)',  # Only match \"Co\" if not part of another word\n",
    "        r'\\bPLC\\b',\n",
    "        r'\\bLLC\\b'\n",
    "    ]\n",
    "    \n",
    "    for pattern in suffix_patterns:\n",
    "        company = re.sub(pattern, '', company, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    # Step 4: Remove trailing urgency/metadata suffixes\n",
    "    urgency_patterns = [\n",
    "        r'\\(?\\s*Urgent\\s*\\)?',\n",
    "        r'\\(?\\s*Immediate\\s+Joiner\\s*\\)?',\n",
    "        r'\\(?\\s*Work\\s+From\\s+Home\\s*\\)?',\n",
    "        r'\\(?\\s*WFH\\s*\\)?',\n",
    "        r'\\(?\\s*Remote\\s*\\)?',\n",
    "        r'\\(?\\s*Hybrid\\s*\\)?'\n",
    "    ]\n",
    "    \n",
    "    for pattern in urgency_patterns:\n",
    "        company = re.sub(pattern, '', company, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    # Step 5: Normalize whitespace (multiple spaces → single space)\n",
    "    company = re.sub(r'\\s+', ' ', company).strip()\n",
    "    \n",
    "    # Step 6: Remove leading/trailing punctuation that might remain\n",
    "    company = re.sub(r'^[,;:\\-|@\\s]+|[,;:\\-|@\\s]+$', '', company).strip()\n",
    "    \n",
    "    # Step 7: Handle empty results\n",
    "    if not company or len(company) < 2:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Step 8: Title case for consistency (optional - comment out if you want original case)\n",
    "    # company = company.title()\n",
    "    \n",
    "    return company\n",
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"Hiring for Google Inc - Urgent\",\n",
    "    \"Posted by: Amazon | Bangalore\",\n",
    "    \"Accenture Pvt Ltd\",\n",
    "    \"Microsoft Corporation\",\n",
    "    \"Wipro\",\n",
    "    \"TCS - Immediate Joiner\",\n",
    "    \"Opening for Infosys Limited\",\n",
    "    \"Now Hiring @ Adobe Inc.\",\n",
    "    \"Flipkart - Work From Home\",\n",
    "    \"Urgent Hiring - Cognizant\",\n",
    "    \"Apple Inc - Remote\",\n",
    "    \"  IBM Corp  \",\n",
    "    \"Oracle Corporation (Urgent)\",\n",
    "    \"\",\n",
    "    None,\n",
    "    \"A\",\n",
    "    \"Posted by Deloitte | Hyderabad | 5 LPA\",\n",
    "    \"Cygnus Professionals\",\n",
    "    \"Centre for Computational Technologies (CCTech)\",\n",
    "    \"Mapmyindia Pvt. Ltd.\",\n",
    "    \"Sirahu Technologies Inc\"\n",
    "]\n",
    "\n",
    "print(\"Testing Company Name Cleaner:\")\n",
    "print(\"-\" * 60)\n",
    "for test in test_cases:\n",
    "    result = clean_company_name(test)\n",
    "    print(f\"Input:  {repr(test):<45} → Output: {result}\")\n",
    "\n",
    "# Example usage with DataFrame\n",
    "df[\"Company_Cleaned\"] = df[\"Company\"].apply(clean_company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2842cec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61a7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Experience Range Extraction:\n",
      "--------------------------------------------------------------------------------\n",
      "Input: '3-5 years'               → Output: (3.0, 5.0)\n",
      "Input: '5 years'                 → Output: (5.0, 5.0)\n",
      "Input: '5+ years'                → Output: (5.0, None)\n",
      "Input: 'Fresher'                 → Output: (0.0, 0.0)\n",
      "Input: 'Entry Level'             → Output: (0.0, 0.0)\n",
      "Input: '0 years'                 → Output: (0.0, 0.0)\n",
      "Input: '3 to 5 years'            → Output: (3.0, 5.0)\n",
      "Input: '2-3 yrs'                 → Output: (2.0, 3.0)\n",
      "Input: '10 Years+'               → Output: (10.0, 10.0)\n",
      "Input: 'No experience'           → Output: (0.0, 0.0)\n",
      "Input: 'No fixed duration'       → Output: (None, None)\n",
      "Input: 'Not fixed'               → Output: (None, None)\n",
      "Input: 'NA'                      → Output: (None, None)\n",
      "Input: '5'                       → Output: (5.0, 5.0)\n",
      "Input: '3.5 years'               → Output: (3.5, 3.5)\n",
      "Input: '1.5-2.5 years'           → Output: (1.5, 2.5)\n",
      "Input: '10-5 years'              → Output: (5.0, 10.0)\n",
      "Input: '  7 years  '             → Output: (7.0, 7.0)\n",
      "Input: ''                        → Output: (None, None)\n",
      "Input: None                      → Output: (None, None)\n",
      "Input: 'Not Mentioned'           → Output: (None, None)\n",
      "Input: '0-1 years'               → Output: (0.0, 1.0)\n",
      "Input: '15+ yrs'                 → Output: (15.0, None)\n",
      "\n",
      "================================================================================\n",
      "Example DataFrame Usage:\n",
      "================================================================================\n",
      "          Experience Experience_Range  Min_Experience  Max_Experience\n",
      "0          3-5 years       (3.0, 5.0)             3.0             5.0\n",
      "1            5 years       (5.0, 5.0)             5.0             5.0\n",
      "2           5+ years      (5.0, None)             5.0             NaN\n",
      "3            Fresher       (0.0, 0.0)             0.0             0.0\n",
      "4  No fixed duration     (None, None)             NaN             NaN\n",
      "5         3 to 5 yrs       (3.0, 5.0)             3.0             5.0\n",
      "6          0-1 years       (0.0, 1.0)             0.0             1.0\n",
      "\n",
      "================================================================================\n",
      "Usage with your actual DataFrame:\n",
      "================================================================================\n",
      "\n",
      "# Apply to your DataFrame:\n",
      "df['Experience_Range'] = df['Experience'].apply(extract_experience_range)\n",
      "df['Min_Experience'] = df['Experience_Range'].apply(get_experience_min)\n",
      "df['Max_Experience'] = df['Experience_Range'].apply(get_experience_max)\n",
      "\n",
      "# Optional: Filter valid experiences\n",
      "df_valid = df[df['Min_Experience'].notna()]\n",
      "\n",
      "# Optional: Filter by experience range\n",
      "df_mid_level = df[(df['Min_Experience'] >= 3) & (df['Max_Experience'] <= 7)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# updated code\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define unexpected/invalid values at module level\n",
    "INVALID_EXPERIENCE_VALUES = [\n",
    "    \"No fixed duration\",\n",
    "    \"Not fixed\",\n",
    "    \"Not Mentioned\",\n",
    "    \"NA\",\n",
    "    \"N/A\",\n",
    "    \"TBD\",\n",
    "    \"To be decided\",\n",
    "    \"Negotiable\"\n",
    "]\n",
    "\n",
    "def extract_experience_range(value: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Extract experience range from the given value.\n",
    "    \n",
    "    Args:\n",
    "        value: The original experience value string\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (min_exp, max_exp) as floats, or (None, None) if invalid\n",
    "        \n",
    "    Examples:\n",
    "        \"3-5 years\" → (3.0, 5.0)\n",
    "        \"5 years\" → (5.0, 5.0)\n",
    "        \"5+ years\" → (5.0, None)\n",
    "        \"Fresher\" → (0.0, 0.0)\n",
    "        \"No fixed duration\" → (None, None)\n",
    "    \"\"\"\n",
    "    # Handle non-string inputs\n",
    "    if not isinstance(value, str) or pd.isna(value):\n",
    "        return (None, None)\n",
    "    \n",
    "    # Clean and normalize input\n",
    "    value = value.strip()\n",
    "    \n",
    "    if not value:\n",
    "        return (None, None)\n",
    "    \n",
    "    # Check if value is in invalid list\n",
    "    if value in INVALID_EXPERIENCE_VALUES:\n",
    "        return (None, None)\n",
    "    \n",
    "    # Pattern 1: Fresher / Entry Level / No Experience\n",
    "    fresher_pattern = r'\\b(fresher|entry[\\s-]?level|no\\s+experience|0\\s*years?)\\b'\n",
    "    if re.search(fresher_pattern, value, re.IGNORECASE):\n",
    "        return (0.0, 0.0)\n",
    "    \n",
    "    # Pattern 2: Range with hyphen or \"to\" (e.g., \"3-5 years\", \"3 to 5 yrs\")\n",
    "    range_pattern = r'(\\d+\\.?\\d*)\\s*(?:-|to)\\s*(\\d+\\.?\\d*)\\s*(?:years?|yrs?)\\b'\n",
    "    match = re.search(range_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        min_exp = float(match.group(1))\n",
    "        max_exp = float(match.group(2))\n",
    "        \n",
    "        # Validate and swap if needed\n",
    "        if min_exp > max_exp:\n",
    "            min_exp, max_exp = max_exp, min_exp\n",
    "        \n",
    "        return (min_exp, max_exp)\n",
    "    \n",
    "    # Pattern 3: Plus sign (e.g., \"5+ years\", \"3+ yrs\")\n",
    "    plus_pattern = r'(\\d+\\.?\\d*)\\s*\\+\\s*(?:years?|yrs?)\\b'\n",
    "    match = re.search(plus_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        exp = float(match.group(1))\n",
    "        return (exp, None)  # Use None for open-ended upper bound\n",
    "    \n",
    "    # Pattern 4: Single value (e.g., \"5 years\", \"3 yrs\")\n",
    "    single_pattern = r'\\b(\\d+\\.?\\d*)\\s*(?:years?|yrs?)\\b'\n",
    "    match = re.search(single_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        exp = float(match.group(1))\n",
    "        return (exp, exp)  # Single value means exact match\n",
    "    \n",
    "    # Pattern 5: Just a number (e.g., \"5\", \"3.5\")\n",
    "    number_pattern = r'\\b(\\d+\\.?\\d*)\\b'\n",
    "    match = re.search(number_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        exp = float(match.group(1))\n",
    "        return (exp, exp)\n",
    "    \n",
    "    # No match found\n",
    "    return (None, None)\n",
    "\n",
    "\n",
    "def get_experience_min(experience_tuple: tuple) -> float:\n",
    "    \"\"\"Extract minimum experience from tuple.\"\"\"\n",
    "    if experience_tuple and experience_tuple[0] is not None:\n",
    "        return experience_tuple[0]\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def get_experience_max(experience_tuple: tuple) -> float:\n",
    "    \"\"\"Extract maximum experience from tuple.\"\"\"\n",
    "    if experience_tuple and experience_tuple[1] is not None:\n",
    "        return experience_tuple[1]\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"3-5 years\",\n",
    "    \"5 years\",\n",
    "    \"5+ years\",\n",
    "    \"Fresher\",\n",
    "    \"Entry Level\",\n",
    "    \"0 years\",\n",
    "    \"3 to 5 years\",\n",
    "    \"2-3 yrs\",\n",
    "    \"10 Years+\",\n",
    "    \"No experience\",\n",
    "    \"No fixed duration\",\n",
    "    \"Not fixed\",\n",
    "    \"NA\",\n",
    "    \"5\",\n",
    "    \"3.5 years\",\n",
    "    \"1.5-2.5 years\",\n",
    "    \"10-5 years\",  # Reversed - should swap\n",
    "    \"  7 years  \",\n",
    "    \"\",\n",
    "    None,\n",
    "    \"Not Mentioned\",\n",
    "    \"0-1 years\",\n",
    "    \"15+ yrs\"\n",
    "]\n",
    "\n",
    "print(\"Testing Experience Range Extraction:\")\n",
    "print(\"-\" * 80)\n",
    "for test in test_cases:\n",
    "    result = extract_experience_range(test)\n",
    "    min_exp = result[0] if result[0] is not None else \"None\"\n",
    "    max_exp = result[1] if result[1] is not None else \"None\"\n",
    "    print(f\"Input: {repr(test):<25} → Output: ({min_exp}, {max_exp})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Example DataFrame Usage:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Example with DataFrame\n",
    "sample_data = {\n",
    "    'Experience': [\n",
    "        \"3-5 years\",\n",
    "        \"5 years\",\n",
    "        \"5+ years\",\n",
    "        \"Fresher\",\n",
    "        \"No fixed duration\",\n",
    "        \"3 to 5 yrs\",\n",
    "        \"0-1 years\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_example = pd.DataFrame(sample_data)\n",
    "\n",
    "# Apply the function\n",
    "df_example['Experience_Range'] = df_example['Experience'].apply(extract_experience_range)\n",
    "df_example['Min_Experience'] = df_example['Experience_Range'].apply(get_experience_min)\n",
    "df_example['Max_Experience'] = df_example['Experience_Range'].apply(get_experience_max)\n",
    "\n",
    "print(df_example)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Usage with your actual DataFrame:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "# Apply to your DataFrame:\n",
    "df['Experience_Range'] = df['Experience'].apply(extract_experience_range)\n",
    "df['Min_Experience'] = df['Experience_Range'].apply(get_experience_min)\n",
    "df['Max_Experience'] = df['Experience_Range'].apply(get_experience_max)\n",
    "\n",
    "# Optional: Filter valid experiences\n",
    "df_valid = df[df['Min_Experience'].notna()]\n",
    "\n",
    "# Optional: Filter by experience range\n",
    "df_mid_level = df[(df['Min_Experience'] >= 3) & (df['Max_Experience'] <= 7)]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d9b81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Experience_Range'] = df['Experience'].apply(extract_experience_range)\n",
    "df['Min_Experience'] = df['Experience_Range'].apply(get_experience_min)\n",
    "df['Max_Experience'] = df['Experience_Range'].apply(get_experience_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f32bc7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Salary Range Extraction:\n",
      "--------------------------------------------------------------------------------\n",
      "Input: '3-5 LPA'                           → Output: (3.0, 5.0)\n",
      "Input: '5-7 Lakhs PA'                      → Output: (5.0, 7.0)\n",
      "Input: '3.5 Lacs'                          → Output: (3.5, 3.5)\n",
      "Input: 'Upto 5 LPA'                        → Output: (0.0, 5.0)\n",
      "Input: '5+ LPA'                            → Output: (5.0, None)\n",
      "Input: 'Not Disclosed'                     → Output: (None, None)\n",
      "Input: '500000-700000'                     → Output: (5.0, 7.0)\n",
      "Input: '600000'                            → Output: (6.0, 6.0)\n",
      "Input: '3 to 5 LPA'                        → Output: (3.0, 5.0)\n",
      "Input: '5 L'                               → Output: (5.0, 5.0)\n",
      "Input: '3-5 L.P.A'                         → Output: (3.0, 5.0)\n",
      "Input: '7 Lakhs Per Annum'                 → Output: (7.0, 7.0)\n",
      "Input: 'Negotiable'                        → Output: (None, None)\n",
      "Input: 'NA'                                → Output: (None, None)\n",
      "Input: '3.5-5.5 Lakhs'                     → Output: (3.5, 5.5)\n",
      "Input: 'Up to 10 LPA'                      → Output: (0.0, 10.0)\n",
      "Input: '8+ Lakhs'                          → Output: (8.0, None)\n",
      "Input: '300000'                            → Output: (3.0, 3.0)\n",
      "Input: '10-5 LPA'                          → Output: (5.0, 10.0)\n",
      "Input: '  5 LPA  '                         → Output: (5.0, 5.0)\n",
      "Input: ''                                  → Output: (None, None)\n",
      "Input: None                                → Output: (None, None)\n",
      "Input: 'As per industry standards'         → Output: (None, None)\n",
      "Input: '1000000-1500000'                   → Output: (10.0, 15.0)\n",
      "Input: '2.5 to 4 L'                        → Output: (2.5, 4.0)\n",
      "\n",
      "================================================================================\n",
      "Example DataFrame Usage:\n",
      "================================================================================\n",
      "          Salary  Salary_Range  Min_Salary  Max_Salary  Avg_Salary\n",
      "0        3-5 LPA    (3.0, 5.0)         3.0         5.0         4.0\n",
      "1        5 Lakhs    (5.0, 5.0)         5.0         5.0         5.0\n",
      "2     Upto 7 LPA    (0.0, 7.0)         0.0         7.0         3.5\n",
      "3         5+ LPA   (5.0, None)         5.0         NaN         5.0\n",
      "4  Not Disclosed  (None, None)         NaN         NaN         NaN\n",
      "5  500000-700000    (5.0, 7.0)         5.0         7.0         6.0\n",
      "6   3 to 5 Lakhs    (3.0, 5.0)         3.0         5.0         4.0\n",
      "\n",
      "================================================================================\n",
      "Usage with your actual DataFrame:\n",
      "================================================================================\n",
      "\n",
      "# Apply to your DataFrame:\n",
      "df['Salary_Range'] = df['Salary'].apply(extract_salary_range)\n",
      "df['Min_Salary'] = df['Salary_Range'].apply(get_salary_min)\n",
      "df['Max_Salary'] = df['Salary_Range'].apply(get_salary_max)\n",
      "df['Avg_Salary'] = df['Salary_Range'].apply(get_salary_avg)\n",
      "\n",
      "# Optional: Filter valid salaries\n",
      "df_valid = df[df['Min_Salary'].notna()]\n",
      "\n",
      "# Optional: Filter by salary range\n",
      "df_mid_range = df[(df['Min_Salary'] >= 3) & (df['Max_Salary'] <= 10)]\n",
      "\n",
      "# Optional: Find jobs with competitive pay (> 5 LPA average)\n",
      "df_high_pay = df[df['Avg_Salary'] > 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# updated Code\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define invalid/undisclosed salary values\n",
    "INVALID_SALARY_VALUES = [\n",
    "    \"Not Disclosed\",\n",
    "    \"Salary Not Disclosed\",\n",
    "    \"NA\",\n",
    "    \"N/A\",\n",
    "    \"Not Mentioned\",\n",
    "    \"Negotiable\",\n",
    "    \"Competitive\",\n",
    "    \"As per industry standards\",\n",
    "    \"TBD\",\n",
    "    \"To be decided\"\n",
    "]\n",
    "\n",
    "def extract_salary_range(value: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Extract salary range from the given value and normalize to Lakhs Per Annum (LPA).\n",
    "    \n",
    "    Args:\n",
    "        value: The original salary value string\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (min_salary, max_salary) as floats in LPA, or (None, None) if invalid\n",
    "        \n",
    "    Examples:\n",
    "        \"3-5 LPA\" → (3.0, 5.0)\n",
    "        \"5 Lakhs\" → (5.0, 5.0)\n",
    "        \"Upto 7 LPA\" → (0.0, 7.0)\n",
    "        \"5+ LPA\" → (5.0, None)\n",
    "        \"500000-700000\" → (5.0, 7.0)  # Converted to Lakhs\n",
    "        \"Not Disclosed\" → (None, None)\n",
    "    \"\"\"\n",
    "    # Handle non-string inputs\n",
    "    if not isinstance(value, str) or pd.isna(value):\n",
    "        return (None, None)\n",
    "    \n",
    "    # Clean and normalize input\n",
    "    value = value.strip()\n",
    "    \n",
    "    if not value:\n",
    "        return (None, None)\n",
    "    \n",
    "    # Check if value is in invalid/undisclosed list (case-insensitive)\n",
    "    if any(value.lower() == invalid.lower() for invalid in INVALID_SALARY_VALUES):\n",
    "        return (None, None)\n",
    "    \n",
    "    # Pattern 1: \"Upto X\" or \"Up to X\" (e.g., \"Upto 5 LPA\", \"Up to 7 Lakhs\")\n",
    "    upto_pattern = r'(?:upto|up\\s*to)\\s*(\\d+\\.?\\d*)\\s*(?:lpa|l\\.?p\\.?a\\.?|lakhs?|lacs?|l)\\b'\n",
    "    match = re.search(upto_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        max_salary = float(match.group(1))\n",
    "        return (0.0, max_salary)\n",
    "    \n",
    "    # Pattern 2: \"X+\" (e.g., \"5+ LPA\", \"3+ Lakhs\")\n",
    "    plus_pattern = r'(\\d+\\.?\\d*)\\s*\\+\\s*(?:lpa|l\\.?p\\.?a\\.?|lakhs?|lacs?|l)\\b'\n",
    "    match = re.search(plus_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        min_salary = float(match.group(1))\n",
    "        return (min_salary, None)\n",
    "    \n",
    "    # Pattern 3: Range with LPA/Lakhs/Lacs units (e.g., \"3-5 LPA\", \"3 to 5 Lakhs\")\n",
    "    range_with_unit_pattern = r'(\\d+\\.?\\d*)\\s*(?:-|to)\\s*(\\d+\\.?\\d*)\\s*(?:lpa|l\\.?p\\.?a\\.?|lakhs?|lacs?|l)(?:\\s*p\\.?a\\.?|\\s*per\\s*annum)?\\b'\n",
    "    match = re.search(range_with_unit_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        min_salary = float(match.group(1))\n",
    "        max_salary = float(match.group(2))\n",
    "        \n",
    "        # Validate and swap if needed\n",
    "        if min_salary > max_salary:\n",
    "            min_salary, max_salary = max_salary, min_salary\n",
    "        \n",
    "        return (min_salary, max_salary)\n",
    "    \n",
    "    # Pattern 4: Single value with LPA/Lakhs/Lacs (e.g., \"5 LPA\", \"3.5 Lakhs\")\n",
    "    single_with_unit_pattern = r'(\\d+\\.?\\d*)\\s*(?:lpa|l\\.?p\\.?a\\.?|lakhs?|lacs?|l)(?:\\s*p\\.?a\\.?|\\s*per\\s*annum)?\\b'\n",
    "    match = re.search(single_with_unit_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        salary = float(match.group(1))\n",
    "        return (salary, salary)\n",
    "    \n",
    "    # Pattern 5: Absolute numbers range (e.g., \"500000-700000\", \"50000 to 70000\")\n",
    "    # Convert to Lakhs (divide by 100,000)\n",
    "    absolute_range_pattern = r'(\\d{5,})\\s*(?:-|to)\\s*(\\d{5,})'\n",
    "    match = re.search(absolute_range_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        min_salary = float(match.group(1)) / 100000  # Convert to Lakhs\n",
    "        max_salary = float(match.group(2)) / 100000\n",
    "        \n",
    "        # Validate and swap if needed\n",
    "        if min_salary > max_salary:\n",
    "            min_salary, max_salary = max_salary, min_salary\n",
    "        \n",
    "        # Round to 2 decimal places\n",
    "        return (round(min_salary, 2), round(max_salary, 2))\n",
    "    \n",
    "    # Pattern 6: Single absolute number (e.g., \"600000\", \"500000\")\n",
    "    # Convert to Lakhs if >= 10000 (assume it's in rupees, not lakhs)\n",
    "    absolute_single_pattern = r'(\\d{5,})'\n",
    "    match = re.search(absolute_single_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        salary = float(match.group(1)) / 100000  # Convert to Lakhs\n",
    "        salary = round(salary, 2)\n",
    "        return (salary, salary)\n",
    "    \n",
    "    # Pattern 7: Just numbers with range (fallback, e.g., \"3-5\", \"5 to 7\")\n",
    "    # Assume already in Lakhs if no unit specified and numbers are small\n",
    "    simple_range_pattern = r'(\\d+\\.?\\d*)\\s*(?:-|to)\\s*(\\d+\\.?\\d*)'\n",
    "    match = re.search(simple_range_pattern, value, re.IGNORECASE)\n",
    "    if match:\n",
    "        min_salary = float(match.group(1))\n",
    "        max_salary = float(match.group(2))\n",
    "        \n",
    "        # Only accept if numbers are reasonable for Lakhs (< 100)\n",
    "        if min_salary < 100 and max_salary < 100:\n",
    "            if min_salary > max_salary:\n",
    "                min_salary, max_salary = max_salary, min_salary\n",
    "            return (min_salary, max_salary)\n",
    "    \n",
    "    # No match found\n",
    "    return (None, None)\n",
    "\n",
    "\n",
    "def get_salary_min(salary_tuple: tuple) -> float:\n",
    "    \"\"\"Extract minimum salary from tuple.\"\"\"\n",
    "    if salary_tuple and salary_tuple[0] is not None:\n",
    "        return salary_tuple[0]\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def get_salary_max(salary_tuple: tuple) -> float:\n",
    "    \"\"\"Extract maximum salary from tuple.\"\"\"\n",
    "    if salary_tuple and salary_tuple[1] is not None:\n",
    "        return salary_tuple[1]\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def get_salary_avg(salary_tuple: tuple) -> float:\n",
    "    \"\"\"Calculate average salary from tuple.\"\"\"\n",
    "    if salary_tuple and salary_tuple[0] is not None and salary_tuple[1] is not None:\n",
    "        return round((salary_tuple[0] + salary_tuple[1]) / 2, 2)\n",
    "    elif salary_tuple and salary_tuple[0] is not None:\n",
    "        return salary_tuple[0]\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"3-5 LPA\",\n",
    "    \"5-7 Lakhs PA\",\n",
    "    \"3.5 Lacs\",\n",
    "    \"Upto 5 LPA\",\n",
    "    \"5+ LPA\",\n",
    "    \"Not Disclosed\",\n",
    "    \"500000-700000\",\n",
    "    \"600000\",\n",
    "    \"3 to 5 LPA\",\n",
    "    \"5 L\",\n",
    "    \"3-5 L.P.A\",\n",
    "    \"7 Lakhs Per Annum\",\n",
    "    \"Negotiable\",\n",
    "    \"NA\",\n",
    "    \"3.5-5.5 Lakhs\",\n",
    "    \"Up to 10 LPA\",\n",
    "    \"8+ Lakhs\",\n",
    "    \"300000\",\n",
    "    \"10-5 LPA\",  # Reversed - should swap\n",
    "    \"  5 LPA  \",\n",
    "    \"\",\n",
    "    None,\n",
    "    \"As per industry standards\",\n",
    "    \"1000000-1500000\",  # 10-15 Lakhs\n",
    "    \"2.5 to 4 L\"\n",
    "]\n",
    "\n",
    "print(\"Testing Salary Range Extraction:\")\n",
    "print(\"-\" * 80)\n",
    "for test in test_cases:\n",
    "    result = extract_salary_range(test)\n",
    "    min_sal = result[0] if result[0] is not None else \"None\"\n",
    "    max_sal = result[1] if result[1] is not None else \"None\"\n",
    "    print(f\"Input: {repr(test):<35} → Output: ({min_sal}, {max_sal})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Example DataFrame Usage:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Example with DataFrame\n",
    "sample_data = {\n",
    "    'Salary': [\n",
    "        \"3-5 LPA\",\n",
    "        \"5 Lakhs\",\n",
    "        \"Upto 7 LPA\",\n",
    "        \"5+ LPA\",\n",
    "        \"Not Disclosed\",\n",
    "        \"500000-700000\",\n",
    "        \"3 to 5 Lakhs\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_example = pd.DataFrame(sample_data)\n",
    "\n",
    "# Apply the function\n",
    "df_example['Salary_Range'] = df_example['Salary'].apply(extract_salary_range)\n",
    "df_example['Min_Salary'] = df_example['Salary_Range'].apply(get_salary_min)\n",
    "df_example['Max_Salary'] = df_example['Salary_Range'].apply(get_salary_max)\n",
    "df_example['Avg_Salary'] = df_example['Salary_Range'].apply(get_salary_avg)\n",
    "\n",
    "print(df_example)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Usage with your actual DataFrame:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "# Apply to your DataFrame:\n",
    "df['Salary_Range'] = df['Salary'].apply(extract_salary_range)\n",
    "df['Min_Salary'] = df['Salary_Range'].apply(get_salary_min)\n",
    "df['Max_Salary'] = df['Salary_Range'].apply(get_salary_max)\n",
    "df['Avg_Salary'] = df['Salary_Range'].apply(get_salary_avg)\n",
    "\n",
    "# Optional: Filter valid salaries\n",
    "df_valid = df[df['Min_Salary'].notna()]\n",
    "\n",
    "# Optional: Filter by salary range\n",
    "df_mid_range = df[(df['Min_Salary'] >= 3) & (df['Max_Salary'] <= 10)]\n",
    "\n",
    "# Optional: Find jobs with competitive pay (> 5 LPA average)\n",
    "df_high_pay = df[df['Avg_Salary'] > 5]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66f415d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Salary_Range'] = df['Salary'].apply(extract_salary_range)\n",
    "df['Min_Salary'] = df['Salary_Range'].apply(get_salary_min)\n",
    "df['Max_Salary'] = df['Salary_Range'].apply(get_salary_max)\n",
    "df['Avg_Salary'] = df['Salary_Range'].apply(get_salary_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1582f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Education Cleaning:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: 'UG: B.Tech/B.E. in Computer Science, PG: M.Tech in Artificial Intelligence'\n",
      "  UG: B.Tech | Computer Science\n",
      "  PG: M.Tech | Artificial Intelligence\n",
      "\n",
      "Input: 'UG: Any Graduate, PG: Any Postgraduate'                              \n",
      "  UG: Not Required | None\n",
      "  PG: Not Required | None\n",
      "\n",
      "Input: 'UG: B.Tech/B.E. in Mechanical'                                       \n",
      "  UG: B.Tech | Mechanical\n",
      "  PG: None | None\n",
      "\n",
      "Input: 'UG: BCA in Computer Applications'                                    \n",
      "  UG: BCA | Computer Applications\n",
      "  PG: None | None\n",
      "\n",
      "Input: 'UG: B.Sc in Physics, PG: M.Sc in Data Science'                       \n",
      "  UG: B.Sc | Physics\n",
      "  PG: M.Sc | Data Science\n",
      "\n",
      "Input: 'UG: Bachelor of Technology in ECE'                                   \n",
      "  UG: Technology | ECE\n",
      "  PG: None | None\n",
      "\n",
      "Input: 'UG: Not Required, PG: MBA'                                           \n",
      "  UG: Not Required | None\n",
      "  PG: Not Required | None\n",
      "\n",
      "Input: 'UG: Diploma in Engineering'                                          \n",
      "  UG: Diploma | Engineering\n",
      "  PG: None | None\n",
      "\n",
      "Input: 'PG: Ph.D in Machine Learning'                                        \n",
      "  UG: None | None\n",
      "  PG: Ph.D | Machine Learning\n",
      "\n",
      "Input: ''                                                                    \n",
      "  UG: None | None\n",
      "  PG: None | None\n",
      "\n",
      "Input: None                                                                  \n",
      "  UG: None | None\n",
      "  PG: None | None\n",
      "\n",
      "Input: 'UG: B.Tech/B.E. in Any Specialization, PG: M.Tech in VLSI'           \n",
      "  UG: Not Required | None\n",
      "  PG: Not Required | None\n",
      "\n",
      "Input: 'UG: Any Graduate'                                                    \n",
      "  UG: Not Required | None\n",
      "  PG: None | None\n",
      "\n",
      "Input: 'UG: BBA, PG: MBA in Finance'                                         \n",
      "  UG: BBA | Any Specialization\n",
      "  PG: MBA | Finance\n",
      "\n",
      "====================================================================================================\n",
      "Example DataFrame Usage:\n",
      "====================================================================================================\n",
      "                                           Education     UG_Degree  \\\n",
      "0  UG: B.Tech/B.E. in Computer Science, PG: M.Tec...        B.Tech   \n",
      "1             UG: Any Graduate, PG: Any Postgraduate  Not Required   \n",
      "2                   UG: BCA in Computer Applications           BCA   \n",
      "3                          UG: Not Required, PG: MBA  Not Required   \n",
      "4                                               None          None   \n",
      "\n",
      "       UG_Specialization     PG_Degree PG_Specialization  \n",
      "0       Computer Science        M.Tech                AI  \n",
      "1                   None  Not Required              None  \n",
      "2  Computer Applications          None              None  \n",
      "3                   None  Not Required              None  \n",
      "4                   None          None              None  \n",
      "\n",
      "====================================================================================================\n",
      "Recommended Usage:\n",
      "====================================================================================================\n",
      "\n",
      "# Apply cleaning\n",
      "df['Education_Cleaned'] = df['Education'].apply(clean_education)\n",
      "\n",
      "# Extract to separate columns for easy filtering\n",
      "df['UG_Degree'] = df['Education_Cleaned'].apply(lambda x: x['UG_Degree'])\n",
      "df['UG_Specialization'] = df['Education_Cleaned'].apply(lambda x: x['UG_Specialization'])\n",
      "df['PG_Degree'] = df['Education_Cleaned'].apply(lambda x: x['PG_Degree'])\n",
      "df['PG_Specialization'] = df['Education_Cleaned'].apply(lambda x: x['PG_Specialization'])\n",
      "\n",
      "# Example queries:\n",
      "# Find all B.Tech Computer Science jobs\n",
      "df_cs_jobs = df[df['UG_Specialization'].str.contains('Computer', na=False)]\n",
      "\n",
      "# Find jobs requiring PG degree\n",
      "df_pg_required = df[df['PG_Degree'].notna() & (df['PG_Degree'] != 'Not Required')]\n",
      "\n",
      "# Count by degree type\n",
      "df['UG_Degree'].value_counts()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_education(value: str) -> dict:\n",
    "    \"\"\"\n",
    "    Clean education value by extracting and normalizing UG and PG details.\n",
    "    \n",
    "    Args:\n",
    "        value: Original education string (e.g., \"UG: B.Tech/B.E. in Computer Science, PG: M.Tech in AI\")\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with keys: UG_Degree, UG_Specialization, PG_Degree, PG_Specialization\n",
    "        \n",
    "    Examples:\n",
    "        \"UG: B.Tech/B.E. in Computer Science\" \n",
    "        → {\"UG_Degree\": \"B.Tech\", \"UG_Specialization\": \"Computer Science\", \n",
    "           \"PG_Degree\": None, \"PG_Specialization\": None}\n",
    "    \"\"\"\n",
    "    # Default structure\n",
    "    result = {\n",
    "        \"UG_Degree\": None,\n",
    "        \"UG_Specialization\": None,\n",
    "        \"PG_Degree\": None,\n",
    "        \"PG_Specialization\": None\n",
    "    }\n",
    "    \n",
    "    # Handle invalid inputs\n",
    "    if not isinstance(value, str) or pd.isna(value) or not value.strip():\n",
    "        return result\n",
    "    \n",
    "    value = value.strip()\n",
    "    \n",
    "    # Check for \"Not Required\" patterns\n",
    "    if re.search(r'\\b(not required|not specified|any|na|n/a)\\b', value, re.IGNORECASE):\n",
    "        if \"UG\" in value:\n",
    "            result[\"UG_Degree\"] = \"Not Required\"\n",
    "        if \"PG\" in value:\n",
    "            result[\"PG_Degree\"] = \"Not Required\"\n",
    "        return result\n",
    "    \n",
    "    # Extract UG and PG sections\n",
    "    pattern = r'(UG|PG):\\s*(.*?)(?=\\s*(?:UG|PG):|$)'\n",
    "    matches = re.findall(pattern, value, re.IGNORECASE)\n",
    "    \n",
    "    for level, content in matches:\n",
    "        level = level.upper()\n",
    "        content = content.strip().rstrip(',').strip()\n",
    "        \n",
    "        if not content:\n",
    "            continue\n",
    "        \n",
    "        # Check for \"Any Graduate\" pattern\n",
    "        if re.search(r'\\bany\\s+(graduate|postgraduate)\\b', content, re.IGNORECASE):\n",
    "            if level == \"UG\":\n",
    "                result[\"UG_Degree\"] = \"Any Graduate\"\n",
    "            else:\n",
    "                result[\"PG_Degree\"] = \"Any Postgraduate\"\n",
    "            continue\n",
    "        \n",
    "        # Extract degree and specialization\n",
    "        # Pattern: \"B.Tech/B.E. in Computer Science\" or \"M.Tech in AI\"\n",
    "        degree_spec_pattern = r'([A-Za-z./]+(?:\\s*\\/\\s*[A-Za-z./]+)*)\\s+in\\s+(.+)'\n",
    "        match = re.search(degree_spec_pattern, content, re.IGNORECASE)\n",
    "        \n",
    "        if match:\n",
    "            degree = match.group(1).strip()\n",
    "            specialization = match.group(2).strip()\n",
    "            \n",
    "            # Normalize degree\n",
    "            degree = normalize_degree(degree)\n",
    "            \n",
    "            if level == \"UG\":\n",
    "                result[\"UG_Degree\"] = degree\n",
    "                result[\"UG_Specialization\"] = specialization\n",
    "            else:\n",
    "                result[\"PG_Degree\"] = degree\n",
    "                result[\"PG_Specialization\"] = specialization\n",
    "        else:\n",
    "            # No \"in\" keyword - treat entire content as degree\n",
    "            degree = normalize_degree(content)\n",
    "            \n",
    "            if level == \"UG\":\n",
    "                result[\"UG_Degree\"] = degree\n",
    "                result[\"UG_Specialization\"] = \"Any Specialization\"\n",
    "            else:\n",
    "                result[\"PG_Degree\"] = degree\n",
    "                result[\"PG_Specialization\"] = \"Any Specialization\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def normalize_degree(degree: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize degree names to standard format.\n",
    "    \n",
    "    Examples:\n",
    "        \"B.Tech/B.E.\" → \"B.Tech\"\n",
    "        \"Bachelor of Technology\" → \"B.Tech\"\n",
    "        \"M.Tech\" → \"M.Tech\"\n",
    "    \"\"\"\n",
    "    degree = degree.strip()\n",
    "    \n",
    "    # Common degree mappings\n",
    "    degree_map = {\n",
    "        # Undergraduate\n",
    "        r'\\b(b\\.?tech|b\\.?e\\.?|bachelor\\s+of\\s+technology|bachelor\\s+of\\s+engineering)\\b': 'B.Tech',\n",
    "        r'\\b(bca|bachelor\\s+of\\s+computer\\s+applications?)\\b': 'BCA',\n",
    "        r'\\b(bsc|b\\.?sc\\.?|bachelor\\s+of\\s+science)\\b': 'B.Sc',\n",
    "        r'\\b(bcom|b\\.?com\\.?|bachelor\\s+of\\s+commerce)\\b': 'B.Com',\n",
    "        r'\\b(ba|b\\.?a\\.?|bachelor\\s+of\\s+arts)\\b': 'B.A',\n",
    "        r'\\b(bba|bachelor\\s+of\\s+business\\s+administration)\\b': 'BBA',\n",
    "        r'\\b(diploma)\\b': 'Diploma',\n",
    "        \n",
    "        # Postgraduate\n",
    "        r'\\b(m\\.?tech|m\\.?e\\.?|master\\s+of\\s+technology|master\\s+of\\s+engineering)\\b': 'M.Tech',\n",
    "        r'\\b(mca|master\\s+of\\s+computer\\s+applications?)\\b': 'MCA',\n",
    "        r'\\b(msc|m\\.?sc\\.?|master\\s+of\\s+science)\\b': 'M.Sc',\n",
    "        r'\\b(mba|master\\s+of\\s+business\\s+administration)\\b': 'MBA',\n",
    "        r'\\b(ma|m\\.?a\\.?|master\\s+of\\s+arts)\\b': 'M.A',\n",
    "        r'\\b(phd|ph\\.?d\\.?|doctorate)\\b': 'Ph.D',\n",
    "        r'\\b(mcom|m\\.?com\\.?|master\\s+of\\s+commerce)\\b': 'M.Com',\n",
    "    }\n",
    "    \n",
    "    for pattern, normalized in degree_map.items():\n",
    "        if re.search(pattern, degree, re.IGNORECASE):\n",
    "            return normalized\n",
    "    \n",
    "    # If no match, return cleaned version\n",
    "    return degree.replace('/', ' ').strip()\n",
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"UG: B.Tech/B.E. in Computer Science, PG: M.Tech in Artificial Intelligence\",\n",
    "    \"UG: Any Graduate, PG: Any Postgraduate\",\n",
    "    \"UG: B.Tech/B.E. in Mechanical\",\n",
    "    \"UG: BCA in Computer Applications\",\n",
    "    \"UG: B.Sc in Physics, PG: M.Sc in Data Science\",\n",
    "    \"UG: Bachelor of Technology in ECE\",\n",
    "    \"UG: Not Required, PG: MBA\",\n",
    "    \"UG: Diploma in Engineering\",\n",
    "    \"PG: Ph.D in Machine Learning\",\n",
    "    \"\",\n",
    "    None,\n",
    "    \"UG: B.Tech/B.E. in Any Specialization, PG: M.Tech in VLSI\",\n",
    "    \"UG: Any Graduate\",\n",
    "    \"UG: BBA, PG: MBA in Finance\"\n",
    "]\n",
    "\n",
    "print(\"Testing Education Cleaning:\")\n",
    "print(\"-\" * 100)\n",
    "for test in test_cases:\n",
    "    result = clean_education(test)\n",
    "    print(f\"Input: {repr(test):<70}\")\n",
    "    print(f\"  UG: {result['UG_Degree']} | {result['UG_Specialization']}\")\n",
    "    print(f\"  PG: {result['PG_Degree']} | {result['PG_Specialization']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"Example DataFrame Usage:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Example with DataFrame\n",
    "sample_data = {\n",
    "    'Education': [\n",
    "        \"UG: B.Tech/B.E. in Computer Science, PG: M.Tech in AI\",\n",
    "        \"UG: Any Graduate, PG: Any Postgraduate\",\n",
    "        \"UG: BCA in Computer Applications\",\n",
    "        \"UG: Not Required, PG: MBA\",\n",
    "        None\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_example = pd.DataFrame(sample_data)\n",
    "\n",
    "# Apply the function\n",
    "df_example['Education_Cleaned'] = df_example['Education'].apply(clean_education)\n",
    "\n",
    "# Extract into separate columns\n",
    "df_example['UG_Degree'] = df_example['Education_Cleaned'].apply(lambda x: x['UG_Degree'])\n",
    "df_example['UG_Specialization'] = df_example['Education_Cleaned'].apply(lambda x: x['UG_Specialization'])\n",
    "df_example['PG_Degree'] = df_example['Education_Cleaned'].apply(lambda x: x['PG_Degree'])\n",
    "df_example['PG_Specialization'] = df_example['Education_Cleaned'].apply(lambda x: x['PG_Specialization'])\n",
    "\n",
    "print(df_example[['Education', 'UG_Degree', 'UG_Specialization', 'PG_Degree', 'PG_Specialization']])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Recommended Usage:\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\"\"\n",
    "# Apply cleaning\n",
    "df['Education_Cleaned'] = df['Education'].apply(clean_education)\n",
    "\n",
    "# Extract to separate columns for easy filtering\n",
    "df['UG_Degree'] = df['Education_Cleaned'].apply(lambda x: x['UG_Degree'])\n",
    "df['UG_Specialization'] = df['Education_Cleaned'].apply(lambda x: x['UG_Specialization'])\n",
    "df['PG_Degree'] = df['Education_Cleaned'].apply(lambda x: x['PG_Degree'])\n",
    "df['PG_Specialization'] = df['Education_Cleaned'].apply(lambda x: x['PG_Specialization'])\n",
    "\n",
    "# Example queries:\n",
    "# Find all B.Tech Computer Science jobs\n",
    "df_cs_jobs = df[df['UG_Specialization'].str.contains('Computer', na=False)]\n",
    "\n",
    "# Find jobs requiring PG degree\n",
    "df_pg_required = df[df['PG_Degree'].notna() & (df['PG_Degree'] != 'Not Required')]\n",
    "\n",
    "# Count by degree type\n",
    "df['UG_Degree'].value_counts()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4998ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Education_Cleaned'] = df['Education'].apply(clean_education)\n",
    "\n",
    "df['UG_Degree'] = df['Education_Cleaned'].apply(lambda x: x['UG_Degree'])\n",
    "df['UG_Specialization'] = df['Education_Cleaned'].apply(lambda x: x['UG_Specialization'])\n",
    "df['PG_Degree'] = df['Education_Cleaned'].apply(lambda x: x['PG_Degree'])\n",
    "df['PG_Specialization'] = df['Education_Cleaned'].apply(lambda x: x['PG_Specialization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b71724eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Skills Cleaning:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Star:   'Python, ML, JS'                        \n",
      "Normal: 'SQL, python, machine learning'         \n",
      "Result: ['Python', 'Machine Learning', 'JavaScript', 'SQL']\n",
      "Count:  4 skills\n",
      "\n",
      "Star:   '[React, Node.js]'                      \n",
      "Normal: 'JavaScript, reactjs, nodejs'           \n",
      "Result: ['React', 'Node.js', 'JavaScript']\n",
      "Count:  3 skills\n",
      "\n",
      "Star:   'AWS, Docker, K8s'                      \n",
      "Normal: 'Kubernetes, aws, docker, CI/CD'        \n",
      "Result: ['AWS', 'Docker', 'Kubernetes', 'Ci', 'Cd']\n",
      "Count:  5 skills\n",
      "\n",
      "Star:   ''                                      \n",
      "Normal: 'Python, Java, C++'                     \n",
      "Result: ['Python', 'Java', 'C++']\n",
      "Count:  3 skills\n",
      "\n",
      "Star:   None                                    \n",
      "Normal: 'Machine Learning, Deep Learning'       \n",
      "Result: ['Machine Learning', 'Deep Learning']\n",
      "Count:  2 skills\n",
      "\n",
      "Star:   'Python'                                \n",
      "Normal: None                                    \n",
      "Result: ['Python']\n",
      "Count:  1 skills\n",
      "\n",
      "Star:   'Python, etc, and, SQL'                 \n",
      "Normal: 'good knowledge of ML'                  \n",
      "Result: ['Python', 'SQL', 'Good Knowledge Of Ml']\n",
      "Count:  3 skills\n",
      "\n",
      "Star:   'TensorFlow, PyTorch'                   \n",
      "Normal: 'tensorflow, pytorch, pandas'           \n",
      "Result: ['TensorFlow', 'PyTorch', 'Pandas']\n",
      "Count:  3 skills\n",
      "\n",
      "Star:   'HTML/CSS/JavaScript'                   \n",
      "Normal: 'React|Angular|Vue'                     \n",
      "Result: ['HTML', 'CSS', 'JavaScript', 'React', 'Angular', 'Vue']\n",
      "Count:  6 skills\n",
      "\n",
      "Star:   \"'Python', 'SQL'\"                       \n",
      "Normal: \"['AWS', 'Docker']\"                     \n",
      "Result: ['Python', 'SQL', 'AWS', 'Docker']\n",
      "Count:  4 skills\n",
      "\n",
      "====================================================================================================\n",
      "Example DataFrame Usage:\n",
      "====================================================================================================\n",
      "           Star_Skills                   Normal_Skills  \\\n",
      "0       Python, ML, JS   SQL, python, machine learning   \n",
      "1     [React, Node.js]     JavaScript, reactjs, nodejs   \n",
      "2     AWS, Docker, K8s  Kubernetes, aws, docker, CI/CD   \n",
      "3                 None               Python, Java, C++   \n",
      "4  TensorFlow, PyTorch     tensorflow, pytorch, pandas   \n",
      "\n",
      "                               Combined_Skills  Skill_Count  \n",
      "0  [Python, Machine Learning, JavaScript, SQL]            4  \n",
      "1                 [React, Node.js, JavaScript]            3  \n",
      "2            [AWS, Docker, Kubernetes, Ci, Cd]            5  \n",
      "3                          [Python, Java, C++]            3  \n",
      "4                [TensorFlow, PyTorch, Pandas]            3  \n",
      "\n",
      "====================================================================================================\n",
      "Recommended Usage:\n",
      "====================================================================================================\n",
      "\n",
      "# Apply skills cleaning\n",
      "df['Combined_Skills'] = df.apply(\n",
      "    lambda row: get_combined_skills(row['Star_Skills'], row['Normal_Skills']),\n",
      "    axis=1\n",
      ")\n",
      "\n",
      "df['Skill_Count'] = df['Combined_Skills'].apply(get_skill_count)\n",
      "\n",
      "# Find jobs requiring specific skills\n",
      "df['Requires_Python'] = df['Combined_Skills'].apply(lambda x: has_skill(x, 'Python'))\n",
      "df['Requires_ML'] = df['Combined_Skills'].apply(lambda x: 'Machine Learning' in x if isinstance(x, list) else False)\n",
      "\n",
      "# Filter jobs by skills\n",
      "python_jobs = df[df['Requires_Python']]\n",
      "ml_jobs = df[df['Requires_ML']]\n",
      "\n",
      "# Most common skills (flatten all skill lists)\n",
      "from collections import Counter\n",
      "all_skills = [skill for skills in df['Combined_Skills'] for skill in skills]\n",
      "skill_frequency = Counter(all_skills)\n",
      "print(skill_frequency.most_common(20))\n",
      "\n",
      "# Skills co-occurrence analysis\n",
      "# Find what skills appear together with Python\n",
      "python_jobs_skills = df[df['Requires_Python']]['Combined_Skills']\n",
      "python_cooccurrence = Counter([s for skills in python_jobs_skills for s in skills if s != 'Python'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# updated code:\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import Union, List\n",
    "\n",
    "# Skill normalization mapping (abbreviations and synonyms)\n",
    "SKILL_NORMALIZATION = {\n",
    "    # Programming Languages\n",
    "    'js': 'JavaScript',\n",
    "    'javascript': 'JavaScript',\n",
    "    'reactjs': 'React',\n",
    "    'react.js': 'React',\n",
    "    'nodejs': 'Node.js',\n",
    "    'node.js': 'Node.js',\n",
    "    'node': 'Node.js',\n",
    "    'ts': 'TypeScript',\n",
    "    'typescript': 'TypeScript',\n",
    "    'py': 'Python',\n",
    "    'python': 'Python',\n",
    "    'c++': 'C++',\n",
    "    'cpp': 'C++',\n",
    "    'c#': 'C#',\n",
    "    'csharp': 'C#',\n",
    "    'golang': 'Go',\n",
    "    \n",
    "    # Frameworks & Libraries\n",
    "    'angular.js': 'Angular',\n",
    "    'angularjs': 'Angular',\n",
    "    'vue.js': 'Vue',\n",
    "    'vuejs': 'Vue',\n",
    "    'nextjs': 'Next.js',\n",
    "    'next.js': 'Next.js',\n",
    "    'expressjs': 'Express.js',\n",
    "    'express.js': 'Express.js',\n",
    "    'django': 'Django',\n",
    "    'flask': 'Flask',\n",
    "    'springboot': 'Spring Boot',\n",
    "    'spring boot': 'Spring Boot',\n",
    "    \n",
    "    # Data Science & ML\n",
    "    'ml': 'Machine Learning',\n",
    "    'machine learning': 'Machine Learning',\n",
    "    'ai': 'Artificial Intelligence',\n",
    "    'artificial intelligence': 'Artificial Intelligence',\n",
    "    'dl': 'Deep Learning',\n",
    "    'deep learning': 'Deep Learning',\n",
    "    'nlp': 'Natural Language Processing',\n",
    "    'cv': 'Computer Vision',\n",
    "    'computer vision': 'Computer Vision',\n",
    "    'tensorflow': 'TensorFlow',\n",
    "    'pytorch': 'PyTorch',\n",
    "    'scikit-learn': 'Scikit-learn',\n",
    "    'sklearn': 'Scikit-learn',\n",
    "    'pandas': 'Pandas',\n",
    "    'numpy': 'NumPy',\n",
    "    \n",
    "    # Databases\n",
    "    'sql': 'SQL',\n",
    "    'mysql': 'MySQL',\n",
    "    'postgresql': 'PostgreSQL',\n",
    "    'postgres': 'PostgreSQL',\n",
    "    'mongodb': 'MongoDB',\n",
    "    'mongo': 'MongoDB',\n",
    "    'nosql': 'NoSQL',\n",
    "    'redis': 'Redis',\n",
    "    \n",
    "    # Cloud & DevOps\n",
    "    'aws': 'AWS',\n",
    "    'amazon web services': 'AWS',\n",
    "    'azure': 'Azure',\n",
    "    'gcp': 'Google Cloud Platform',\n",
    "    'google cloud': 'Google Cloud Platform',\n",
    "    'docker': 'Docker',\n",
    "    'kubernetes': 'Kubernetes',\n",
    "    'k8s': 'Kubernetes',\n",
    "    'ci/cd': 'CI/CD',\n",
    "    'jenkins': 'Jenkins',\n",
    "    'git': 'Git',\n",
    "    'github': 'GitHub',\n",
    "    'gitlab': 'GitLab',\n",
    "    \n",
    "    # Other\n",
    "    'api': 'API',\n",
    "    'rest api': 'REST API',\n",
    "    'restful': 'REST API',\n",
    "    'graphql': 'GraphQL',\n",
    "    'html': 'HTML',\n",
    "    'css': 'CSS',\n",
    "    'sass': 'SASS',\n",
    "    'scss': 'SCSS',\n",
    "}\n",
    "\n",
    "# Skills to exclude (noise/invalid)\n",
    "INVALID_SKILLS = {\n",
    "    'etc', 'and', 'or', 'with', 'using', 'knowledge', 'experience',\n",
    "    'skills', 'good', 'strong', 'excellent', 'basic', 'advanced',\n",
    "    'familiarity', 'understanding', 'ability', 'na', 'n/a', 'none',\n",
    "    'required', 'preferred', 'must', 'have', 'plus', 'bonus'\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_skill(skill: str) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Normalize a single skill name.\n",
    "    \n",
    "    Args:\n",
    "        skill: Raw skill string\n",
    "        \n",
    "    Returns:\n",
    "        Normalized skill name or None if invalid\n",
    "    \"\"\"\n",
    "    if not skill or not isinstance(skill, str):\n",
    "        return None\n",
    "    \n",
    "    # Clean whitespace and convert to lowercase for matching\n",
    "    skill = skill.strip().lower()\n",
    "    \n",
    "    # Remove common punctuation at edges\n",
    "    skill = re.sub(r'^[.,;:\\-/|()]+|[.,;:\\-/|()]+$', '', skill).strip()\n",
    "    \n",
    "    # Skip if empty after cleaning\n",
    "    if not skill or len(skill) < 2:\n",
    "        return None\n",
    "    \n",
    "    # Skip if in invalid list\n",
    "    if skill in INVALID_SKILLS:\n",
    "        return None\n",
    "    \n",
    "    # Skip single letters (unless known abbreviations like 'R', 'C')\n",
    "    if len(skill) == 1 and skill not in ['r', 'c']:\n",
    "        return None\n",
    "    \n",
    "    # Normalize using mapping\n",
    "    if skill in SKILL_NORMALIZATION:\n",
    "        return SKILL_NORMALIZATION[skill]\n",
    "    \n",
    "    # Return title-cased version if not in mapping\n",
    "    return skill.title()\n",
    "\n",
    "\n",
    "def parse_skills_string(skills_str: Union[str, List]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse skills from string or list format.\n",
    "    \n",
    "    Args:\n",
    "        skills_str: Skills as string (comma/pipe/semicolon separated) or list\n",
    "        \n",
    "    Returns:\n",
    "        List of individual skill strings\n",
    "    \"\"\"\n",
    "    # Handle None or empty\n",
    "    if pd.isna(skills_str) or not skills_str:\n",
    "        return []\n",
    "    \n",
    "    # If already a list\n",
    "    if isinstance(skills_str, list):\n",
    "        return [str(s).strip() for s in skills_str if s]\n",
    "    \n",
    "    # Convert to string if not already\n",
    "    skills_str = str(skills_str).strip()\n",
    "    \n",
    "    # Remove surrounding brackets if present (e.g., \"[Python, SQL]\")\n",
    "    skills_str = re.sub(r'^\\[|\\]$', '', skills_str)\n",
    "    \n",
    "    # Remove quotes that might wrap skills\n",
    "    skills_str = re.sub(r'[\"\\']', '', skills_str)\n",
    "    \n",
    "    # Split on multiple possible separators: comma, pipe, semicolon, forward slash\n",
    "    skills_list = re.split(r'[,|;/]', skills_str)\n",
    "    \n",
    "    # Clean each skill\n",
    "    skills_list = [s.strip() for s in skills_list if s and s.strip()]\n",
    "    \n",
    "    return skills_list\n",
    "\n",
    "\n",
    "def get_combined_skills(star_skills: Union[str, List], \n",
    "                        normal_skills: Union[str, List],\n",
    "                        preserve_order: bool = True) -> List[str]:\n",
    "    \"\"\"\n",
    "    Combine and normalize star skills and normal skills.\n",
    "    \n",
    "    Args:\n",
    "        star_skills: Primary/featured skills (string or list)\n",
    "        normal_skills: Additional skills (string or list)\n",
    "        preserve_order: If True, star skills appear first (default: True)\n",
    "        \n",
    "    Returns:\n",
    "        List of unique, normalized skills\n",
    "        \n",
    "    Examples:\n",
    "        star_skills = \"Python, ML, JS\"\n",
    "        normal_skills = \"SQL, python, machine learning\"\n",
    "        → [\"Python\", \"Machine Learning\", \"JavaScript\", \"SQL\"]\n",
    "    \"\"\"\n",
    "    # Parse skills from both sources\n",
    "    star_list = parse_skills_string(star_skills)\n",
    "    normal_list = parse_skills_string(normal_skills)\n",
    "    \n",
    "    # Normalize all skills\n",
    "    normalized_star = [normalize_skill(s) for s in star_list]\n",
    "    normalized_normal = [normalize_skill(s) for s in normal_list]\n",
    "    \n",
    "    # Remove None values\n",
    "    normalized_star = [s for s in normalized_star if s is not None]\n",
    "    normalized_normal = [s for s in normalized_normal if s is not None]\n",
    "    \n",
    "    if preserve_order:\n",
    "        # Keep star skills first, then add normal skills not already present\n",
    "        # Use dict to maintain order while deduplicating (Python 3.7+)\n",
    "        seen = {}\n",
    "        for skill in normalized_star:\n",
    "            seen[skill] = None\n",
    "        for skill in normalized_normal:\n",
    "            if skill not in seen:\n",
    "                seen[skill] = None\n",
    "        return list(seen.keys())\n",
    "    else:\n",
    "        # Just deduplicate without preserving order\n",
    "        return list(set(normalized_star + normalized_normal))\n",
    "\n",
    "\n",
    "def get_skill_count(skills_list: List[str]) -> int:\n",
    "    \"\"\"Get count of skills in list.\"\"\"\n",
    "    return len(skills_list) if isinstance(skills_list, list) else 0\n",
    "\n",
    "\n",
    "def has_skill(skills_list: List[str], target_skill: str) -> bool:\n",
    "    \"\"\"Check if target skill is in the skills list (case-insensitive).\"\"\"\n",
    "    if not isinstance(skills_list, list):\n",
    "        return False\n",
    "    target_normalized = normalize_skill(target_skill)\n",
    "    return target_normalized in skills_list if target_normalized else False\n",
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    # (star_skills, normal_skills)\n",
    "    (\"Python, ML, JS\", \"SQL, python, machine learning\"),\n",
    "    (\"[React, Node.js]\", \"JavaScript, reactjs, nodejs\"),\n",
    "    (\"AWS, Docker, K8s\", \"Kubernetes, aws, docker, CI/CD\"),\n",
    "    (\"\", \"Python, Java, C++\"),\n",
    "    (None, \"Machine Learning, Deep Learning\"),\n",
    "    (\"Python\", None),\n",
    "    (\"Python, etc, and, SQL\", \"good knowledge of ML\"),\n",
    "    (\"TensorFlow, PyTorch\", \"tensorflow, pytorch, pandas\"),\n",
    "    (\"HTML/CSS/JavaScript\", \"React|Angular|Vue\"),\n",
    "    (\"'Python', 'SQL'\", \"['AWS', 'Docker']\"),\n",
    "]\n",
    "\n",
    "print(\"Testing Skills Cleaning:\")\n",
    "print(\"-\" * 100)\n",
    "for star, normal in test_cases:\n",
    "    result = get_combined_skills(star, normal)\n",
    "    print(f\"Star:   {repr(star):<40}\")\n",
    "    print(f\"Normal: {repr(normal):<40}\")\n",
    "    print(f\"Result: {result}\")\n",
    "    print(f\"Count:  {len(result)} skills\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"Example DataFrame Usage:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Example with DataFrame\n",
    "sample_data = {\n",
    "    'Star_Skills': [\n",
    "        \"Python, ML, JS\",\n",
    "        \"[React, Node.js]\",\n",
    "        \"AWS, Docker, K8s\",\n",
    "        None,\n",
    "        \"TensorFlow, PyTorch\"\n",
    "    ],\n",
    "    'Normal_Skills': [\n",
    "        \"SQL, python, machine learning\",\n",
    "        \"JavaScript, reactjs, nodejs\",\n",
    "        \"Kubernetes, aws, docker, CI/CD\",\n",
    "        \"Python, Java, C++\",\n",
    "        \"tensorflow, pytorch, pandas\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_example = pd.DataFrame(sample_data)\n",
    "\n",
    "# Apply cleaning\n",
    "df_example['Combined_Skills'] = df_example.apply(\n",
    "    lambda row: get_combined_skills(row['Star_Skills'], row['Normal_Skills']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_example['Skill_Count'] = df_example['Combined_Skills'].apply(get_skill_count)\n",
    "\n",
    "# Check for specific skills\n",
    "df_example['Has_Python'] = df_example['Combined_Skills'].apply(lambda x: has_skill(x, 'Python'))\n",
    "df_example['Has_ML'] = df_example['Combined_Skills'].apply(lambda x: has_skill(x, 'Machine Learning'))\n",
    "\n",
    "print(df_example[['Star_Skills', 'Normal_Skills', 'Combined_Skills', 'Skill_Count']])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Recommended Usage:\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\"\"\n",
    "# Apply skills cleaning\n",
    "df['Combined_Skills'] = df.apply(\n",
    "    lambda row: get_combined_skills(row['Star_Skills'], row['Normal_Skills']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['Skill_Count'] = df['Combined_Skills'].apply(get_skill_count)\n",
    "\n",
    "# Find jobs requiring specific skills\n",
    "df['Requires_Python'] = df['Combined_Skills'].apply(lambda x: has_skill(x, 'Python'))\n",
    "df['Requires_ML'] = df['Combined_Skills'].apply(lambda x: 'Machine Learning' in x if isinstance(x, list) else False)\n",
    "\n",
    "# Filter jobs by skills\n",
    "python_jobs = df[df['Requires_Python']]\n",
    "ml_jobs = df[df['Requires_ML']]\n",
    "\n",
    "# Most common skills (flatten all skill lists)\n",
    "from collections import Counter\n",
    "all_skills = [skill for skills in df['Combined_Skills'] for skill in skills]\n",
    "skill_frequency = Counter(all_skills)\n",
    "print(skill_frequency.most_common(20))\n",
    "\n",
    "# Skills co-occurrence analysis\n",
    "# Find what skills appear together with Python\n",
    "python_jobs_skills = df[df['Requires_Python']]['Combined_Skills']\n",
    "python_cooccurrence = Counter([s for skills in python_jobs_skills for s in skills if s != 'Python'])\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "730e8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Combined_Skills'] = df.apply(\n",
    "    lambda row: get_combined_skills(row['Star_Skills'], row['Normal_Skills']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['Skill_Count'] = df['Combined_Skills'].apply(get_skill_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8478ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Department Cleaning:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input:   'IT/HR/Sales'                                     \n",
      "Output:  ['Information Technology', 'Human Resources', 'Sales']\n",
      "Primary: Information Technology | Count: 3\n",
      "\n",
      "Input:   'Engineering, R&D'                                \n",
      "Output:  ['Engineering']\n",
      "Primary: Engineering | Count: 1\n",
      "\n",
      "Input:   'IT, IT, Information Technology'                  \n",
      "Output:  ['Information Technology']\n",
      "Primary: Information Technology | Count: 1\n",
      "\n",
      "Input:   'Software Development - Quality Assurance'        \n",
      "Output:  ['Software Development', 'Quality Assurance']\n",
      "Primary: Software Development | Count: 2\n",
      "\n",
      "Input:   'Sales & Marketing'                               \n",
      "Output:  ['Sales', 'Marketing']\n",
      "Primary: Sales | Count: 2\n",
      "\n",
      "Input:   'Finance/Accounts/Admin'                          \n",
      "Output:  ['Finance', 'Administration']\n",
      "Primary: Finance | Count: 2\n",
      "\n",
      "Input:   'DevOps | Cloud | Infrastructure'                 \n",
      "Output:  ['DevOps', 'Cloud', 'Infrastructure']\n",
      "Primary: DevOps | Count: 3\n",
      "\n",
      "Input:   'Product Management, Engineering'                 \n",
      "Output:  ['Product Management', 'Engineering']\n",
      "Primary: Product Management | Count: 2\n",
      "\n",
      "Input:   'NA'                                              \n",
      "Output:  []\n",
      "Primary: None | Count: 0\n",
      "\n",
      "Input:   'Not Specified'                                   \n",
      "Output:  []\n",
      "Primary: None | Count: 0\n",
      "\n",
      "Input:   ''                                                \n",
      "Output:  []\n",
      "Primary: None | Count: 0\n",
      "\n",
      "Input:   None                                              \n",
      "Output:  []\n",
      "Primary: None | Count: 0\n",
      "\n",
      "Input:   'IT'                                              \n",
      "Output:  ['Information Technology']\n",
      "Primary: Information Technology | Count: 1\n",
      "\n",
      "Input:   'Human Resources'                                 \n",
      "Output:  ['Human Resources']\n",
      "Primary: Human Resources | Count: 1\n",
      "\n",
      "Input:   'R&D, Product, Engineering'                       \n",
      "Output:  ['Product Management', 'Engineering']\n",
      "Primary: Product Management | Count: 2\n",
      "\n",
      "Input:   'Data Science/Analytics/AI/ML'                    \n",
      "Output:  ['Data Science', 'Analytics', 'Artificial Intelligence', 'Machine Learning']\n",
      "Primary: Data Science | Count: 4\n",
      "\n",
      "Input:   '[Marketing, Sales]'                              \n",
      "Output:  ['Marketing', 'Sales']\n",
      "Primary: Marketing | Count: 2\n",
      "\n",
      "Input:   \"'IT', 'HR', 'Finance'\"                           \n",
      "Output:  ['Information Technology', 'Human Resources', 'Finance']\n",
      "Primary: Information Technology | Count: 3\n",
      "\n",
      "====================================================================================================\n",
      "Example DataFrame Usage:\n",
      "====================================================================================================\n",
      "                        Department  \\\n",
      "0                      IT/HR/Sales   \n",
      "1                 Engineering, R&D   \n",
      "2   IT, IT, Information Technology   \n",
      "3                Sales & Marketing   \n",
      "4                               NA   \n",
      "5  Product Management, Engineering   \n",
      "6                             None   \n",
      "\n",
      "                                 Department_Cleaned      Primary_Department  \\\n",
      "0  [Information Technology, Human Resources, Sales]  Information Technology   \n",
      "1                                     [Engineering]             Engineering   \n",
      "2                          [Information Technology]  Information Technology   \n",
      "3                                [Sales, Marketing]                   Sales   \n",
      "4                                                []                    None   \n",
      "5                 [Product Management, Engineering]      Product Management   \n",
      "6                                                []                    None   \n",
      "\n",
      "   Department_Count  \n",
      "0                 3  \n",
      "1                 1  \n",
      "2                 1  \n",
      "3                 2  \n",
      "4                 0  \n",
      "5                 2  \n",
      "6                 0  \n",
      "\n",
      "====================================================================================================\n",
      "Recommended Usage:\n",
      "====================================================================================================\n",
      "\n",
      "# Apply department cleaning\n",
      "df['Department_Cleaned'] = df['Department'].apply(clean_department)\n",
      "df['Primary_Department'] = df['Department_Cleaned'].apply(get_primary_department)\n",
      "df['Department_Count'] = df['Department_Cleaned'].apply(get_department_count)\n",
      "\n",
      "# Filter by department\n",
      "it_jobs = df[df['Department_Cleaned'].apply(lambda x: has_department(x, 'IT'))]\n",
      "engineering_jobs = df[df['Primary_Department'] == 'Engineering']\n",
      "\n",
      "# Department frequency analysis\n",
      "from collections import Counter\n",
      "all_depts = [dept for depts in df['Department_Cleaned'] for dept in depts]\n",
      "dept_frequency = Counter(all_depts)\n",
      "print(dept_frequency.most_common(20))\n",
      "\n",
      "# Multi-department jobs\n",
      "multi_dept_jobs = df[df['Department_Count'] > 1]\n",
      "\n",
      "# Cross-functional roles (e.g., IT + Sales)\n",
      "it_sales_jobs = df[df['Department_Cleaned'].apply(\n",
      "    lambda x: has_department(x, 'IT') and has_department(x, 'Sales')\n",
      ")]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# updated code:\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List, Union\n",
    "\n",
    "# Department normalization mapping\n",
    "DEPARTMENT_NORMALIZATION = {\n",
    "    # IT & Technology\n",
    "    'it': 'Information Technology',\n",
    "    'information technology': 'Information Technology',\n",
    "    'tech': 'Technology',\n",
    "    'technology': 'Technology',\n",
    "    'software': 'Software Development',\n",
    "    'software development': 'Software Development',\n",
    "    'software engineering': 'Software Engineering',\n",
    "    'engineering': 'Engineering',\n",
    "    'data': 'Data Science',\n",
    "    'data science': 'Data Science',\n",
    "    'analytics': 'Analytics',\n",
    "    'ai': 'Artificial Intelligence',\n",
    "    'ml': 'Machine Learning',\n",
    "    \n",
    "    # Business Functions\n",
    "    'hr': 'Human Resources',\n",
    "    'human resources': 'Human Resources',\n",
    "    'human resource': 'Human Resources',\n",
    "    'finance': 'Finance',\n",
    "    'accounts': 'Finance',\n",
    "    'accounting': 'Finance',\n",
    "    'sales': 'Sales',\n",
    "    'marketing': 'Marketing',\n",
    "    'sales & marketing': 'Sales & Marketing',\n",
    "    'sales and marketing': 'Sales & Marketing',\n",
    "    'operations': 'Operations',\n",
    "    'ops': 'Operations',\n",
    "    'admin': 'Administration',\n",
    "    'administration': 'Administration',\n",
    "    'legal': 'Legal',\n",
    "    \n",
    "    # R&D and Product\n",
    "    'r&d': 'Research & Development',\n",
    "    'research': 'Research & Development',\n",
    "    'research and development': 'Research & Development',\n",
    "    'product': 'Product Management',\n",
    "    'product management': 'Product Management',\n",
    "    'project management': 'Project Management',\n",
    "    'pmo': 'Project Management Office',\n",
    "    \n",
    "    # Operations & Support\n",
    "    'customer service': 'Customer Service',\n",
    "    'customer support': 'Customer Support',\n",
    "    'support': 'Customer Support',\n",
    "    'technical support': 'Technical Support',\n",
    "    'quality': 'Quality Assurance',\n",
    "    'qa': 'Quality Assurance',\n",
    "    'quality assurance': 'Quality Assurance',\n",
    "    'testing': 'Quality Assurance',\n",
    "    \n",
    "    # Design & Creative\n",
    "    'design': 'Design',\n",
    "    'ui/ux': 'UI/UX Design',\n",
    "    'ux': 'UX Design',\n",
    "    'ui': 'UI Design',\n",
    "    'creative': 'Creative',\n",
    "    'graphics': 'Graphics Design',\n",
    "    \n",
    "    # Infrastructure\n",
    "    'devops': 'DevOps',\n",
    "    'infrastructure': 'Infrastructure',\n",
    "    'network': 'Network',\n",
    "    'security': 'Security',\n",
    "    'cybersecurity': 'Cybersecurity',\n",
    "    'cloud': 'Cloud',\n",
    "    \n",
    "    # Manufacturing & Production\n",
    "    'production': 'Production',\n",
    "    'manufacturing': 'Manufacturing',\n",
    "    'supply chain': 'Supply Chain',\n",
    "    'logistics': 'Logistics',\n",
    "    'procurement': 'Procurement',\n",
    "    \n",
    "    # Consulting & Advisory\n",
    "    'consulting': 'Consulting',\n",
    "    'advisory': 'Advisory',\n",
    "    'strategy': 'Strategy',\n",
    "    \n",
    "    # Other\n",
    "    'general': 'General',\n",
    "    'other': 'Other',\n",
    "    'misc': 'Miscellaneous',\n",
    "    'miscellaneous': 'Miscellaneous',\n",
    "}\n",
    "\n",
    "# Invalid department names to exclude\n",
    "INVALID_DEPARTMENTS = {\n",
    "    'na', 'n/a', 'none', 'not specified', 'not mentioned',\n",
    "    'any', 'all', 'multiple', 'various', 'tbd', 'to be decided'\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_department(dept: str) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Normalize a single department name.\n",
    "    \n",
    "    Args:\n",
    "        dept: Raw department string\n",
    "        \n",
    "    Returns:\n",
    "        Normalized department name or None if invalid\n",
    "    \"\"\"\n",
    "    if not dept or not isinstance(dept, str):\n",
    "        return None\n",
    "    \n",
    "    # Clean and normalize\n",
    "    dept = dept.strip().lower()\n",
    "    \n",
    "    # Remove common punctuation at edges\n",
    "    dept = re.sub(r'^[.,;:\\-/|()&]+|[.,;:\\-/|()&]+$', '', dept).strip()\n",
    "    \n",
    "    # Skip if empty or too short\n",
    "    if not dept or len(dept) < 2:\n",
    "        return None\n",
    "    \n",
    "    # Skip if in invalid list\n",
    "    if dept in INVALID_DEPARTMENTS:\n",
    "        return None\n",
    "    \n",
    "    # Normalize using mapping\n",
    "    if dept in DEPARTMENT_NORMALIZATION:\n",
    "        return DEPARTMENT_NORMALIZATION[dept]\n",
    "    \n",
    "    # Return title-cased version if not in mapping\n",
    "    return dept.title()\n",
    "\n",
    "\n",
    "def clean_department(value: Union[str, List]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Clean department value by splitting, normalizing, and deduplicating.\n",
    "    \n",
    "    Args:\n",
    "        value: Department string or list\n",
    "        \n",
    "    Returns:\n",
    "        List of unique, normalized department names\n",
    "        \n",
    "    Examples:\n",
    "        \"IT/HR/Sales\" → [\"Information Technology\", \"Human Resources\", \"Sales\"]\n",
    "        \"Engineering, R&D\" → [\"Engineering\", \"Research & Development\"]\n",
    "        \"IT, IT, Information Technology\" → [\"Information Technology\"]\n",
    "    \"\"\"\n",
    "    # Handle None, NaN, or empty\n",
    "    if pd.isna(value) or not value:\n",
    "        return []\n",
    "    \n",
    "    # If already a list\n",
    "    if isinstance(value, list):\n",
    "        dept_list = [str(d).strip() for d in value if d]\n",
    "    else:\n",
    "        # Convert to string\n",
    "        value = str(value).strip()\n",
    "        \n",
    "        # Remove surrounding brackets if present\n",
    "        value = re.sub(r'^\\[|\\]$', '', value)\n",
    "        \n",
    "        # Remove quotes\n",
    "        value = re.sub(r'[\"\\']', '', value)\n",
    "        \n",
    "        # Split on multiple separators: comma, slash, hyphen, pipe, ampersand\n",
    "        # Use regex to split on any of these characters\n",
    "        dept_list = re.split(r'[,/\\-|&]', value)\n",
    "        \n",
    "        # Clean each department\n",
    "        dept_list = [d.strip() for d in dept_list if d and d.strip()]\n",
    "    \n",
    "    # Normalize all departments\n",
    "    normalized = [normalize_department(d) for d in dept_list]\n",
    "    \n",
    "    # Remove None values and deduplicate while preserving order\n",
    "    seen = {}\n",
    "    for dept in normalized:\n",
    "        if dept is not None:\n",
    "            seen[dept] = None\n",
    "    \n",
    "    return list(seen.keys())\n",
    "\n",
    "\n",
    "def get_primary_department(dept_list: List[str]) -> Union[str, None]:\n",
    "    \"\"\"Get the first (primary) department from list.\"\"\"\n",
    "    return dept_list[0] if dept_list else None\n",
    "\n",
    "\n",
    "def has_department(dept_list: List[str], target_dept: str) -> bool:\n",
    "    \"\"\"Check if target department is in list (case-insensitive).\"\"\"\n",
    "    if not isinstance(dept_list, list):\n",
    "        return False\n",
    "    target_normalized = normalize_department(target_dept)\n",
    "    return target_normalized in dept_list if target_normalized else False\n",
    "\n",
    "\n",
    "def get_department_count(dept_list: List[str]) -> int:\n",
    "    \"\"\"Get count of departments.\"\"\"\n",
    "    return len(dept_list) if isinstance(dept_list, list) else 0\n",
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"IT/HR/Sales\",\n",
    "    \"Engineering, R&D\",\n",
    "    \"IT, IT, Information Technology\",\n",
    "    \"Software Development - Quality Assurance\",\n",
    "    \"Sales & Marketing\",\n",
    "    \"Finance/Accounts/Admin\",\n",
    "    \"DevOps | Cloud | Infrastructure\",\n",
    "    \"Product Management, Engineering\",\n",
    "    \"NA\",\n",
    "    \"Not Specified\",\n",
    "    \"\",\n",
    "    None,\n",
    "    \"IT\",\n",
    "    \"Human Resources\",\n",
    "    \"R&D, Product, Engineering\",\n",
    "    \"Data Science/Analytics/AI/ML\",\n",
    "    \"[Marketing, Sales]\",\n",
    "    \"'IT', 'HR', 'Finance'\",\n",
    "]\n",
    "\n",
    "print(\"Testing Department Cleaning:\")\n",
    "print(\"-\" * 100)\n",
    "for test in test_cases:\n",
    "    result = clean_department(test)\n",
    "    primary = get_primary_department(result)\n",
    "    count = get_department_count(result)\n",
    "    print(f\"Input:   {repr(test):<50}\")\n",
    "    print(f\"Output:  {result}\")\n",
    "    print(f\"Primary: {primary} | Count: {count}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"Example DataFrame Usage:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Example with DataFrame\n",
    "sample_data = {\n",
    "    'Department': [\n",
    "        \"IT/HR/Sales\",\n",
    "        \"Engineering, R&D\",\n",
    "        \"IT, IT, Information Technology\",\n",
    "        \"Sales & Marketing\",\n",
    "        \"NA\",\n",
    "        \"Product Management, Engineering\",\n",
    "        None\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_example = pd.DataFrame(sample_data)\n",
    "\n",
    "# Apply cleaning\n",
    "df_example['Department_Cleaned'] = df_example['Department'].apply(clean_department)\n",
    "df_example['Primary_Department'] = df_example['Department_Cleaned'].apply(get_primary_department)\n",
    "df_example['Department_Count'] = df_example['Department_Cleaned'].apply(get_department_count)\n",
    "\n",
    "# Check for specific departments\n",
    "df_example['Has_IT'] = df_example['Department_Cleaned'].apply(lambda x: has_department(x, 'IT'))\n",
    "df_example['Has_Engineering'] = df_example['Department_Cleaned'].apply(lambda x: has_department(x, 'Engineering'))\n",
    "\n",
    "print(df_example[['Department', 'Department_Cleaned', 'Primary_Department', 'Department_Count']])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Recommended Usage:\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\"\"\n",
    "# Apply department cleaning\n",
    "df['Department_Cleaned'] = df['Department'].apply(clean_department)\n",
    "df['Primary_Department'] = df['Department_Cleaned'].apply(get_primary_department)\n",
    "df['Department_Count'] = df['Department_Cleaned'].apply(get_department_count)\n",
    "\n",
    "# Filter by department\n",
    "it_jobs = df[df['Department_Cleaned'].apply(lambda x: has_department(x, 'IT'))]\n",
    "engineering_jobs = df[df['Primary_Department'] == 'Engineering']\n",
    "\n",
    "# Department frequency analysis\n",
    "from collections import Counter\n",
    "all_depts = [dept for depts in df['Department_Cleaned'] for dept in depts]\n",
    "dept_frequency = Counter(all_depts)\n",
    "print(dept_frequency.most_common(20))\n",
    "\n",
    "# Multi-department jobs\n",
    "multi_dept_jobs = df[df['Department_Count'] > 1]\n",
    "\n",
    "# Cross-functional roles (e.g., IT + Sales)\n",
    "it_sales_jobs = df[df['Department_Cleaned'].apply(\n",
    "    lambda x: has_department(x, 'IT') and has_department(x, 'Sales')\n",
    ")]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55f699b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Department_Cleaned'] = df['Department'].apply(clean_department)\n",
    "df['Primary_Department'] = df['Department_Cleaned'].apply(get_primary_department)\n",
    "df['Department_Count'] = df['Department_Cleaned'].apply(get_department_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2caea5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3480     2025-12-13\n",
       "12088    2025-12-19\n",
       "8243     2025-12-16\n",
       "291      2025-12-07\n",
       "5780     2025-12-14\n",
       "12341    2025-12-19\n",
       "9551     2025-12-17\n",
       "7520     2025-12-15\n",
       "7688     2025-12-15\n",
       "7745     2025-12-15\n",
       "Name: Scraped_At_Cleaned, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_timestamp(value: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the timestamp value by extracting the date part.\n",
    "    \n",
    "    Args:\n",
    "        value: The original timestamp value.\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned date string in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, str):\n",
    "        return value\n",
    "\n",
    "    # Split by \"T\" and take the first part\n",
    "    date_part = value.split(\"T\")[0]\n",
    "    \n",
    "    return date_part\n",
    "\n",
    "df[\"Scraped_At_Cleaned\"] = df[\"Scraped_At\"].apply(lambda x: clean_timestamp(x))\n",
    "df[\"Scraped_At_Cleaned\"].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9461f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "906f420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14410    Designing and developing new web applications....\n",
       "6367     Role: Talent Acquisition Specialist Location: ...\n",
       "7227     About The Role Project Role : Custom Software ...\n",
       "10359    Job Summary: As a Microsoft Dynamics 365 CRM A...\n",
       "1674     What Youll Do As a UX Designer, youll work acr...\n",
       "7503     1) Expert-Level Technical Support: Provide exp...\n",
       "11310    Job Purpose Skilled Python Developer with 2+ y...\n",
       "4954     Looking for a QA Engineer who is versed in fun...\n",
       "9326     Overall 5+ years of experience in the Banking ...\n",
       "12437    Responsibilities Collaborate with cross-functi...\n",
       "Name: Description_Cleaned, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_description(value: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the job description by removing unwanted characters.\n",
    "    \n",
    "    Args:\n",
    "        value: The original job description.\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned job description string.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, str):\n",
    "        return value\n",
    "\n",
    "    # Example cleaning: Remove excessive whitespace\n",
    "    cleaned_description = ' '.join(value.split())\n",
    "    \n",
    "    return cleaned_description\n",
    "\n",
    "df[\"Description_Cleaned\"] = df[\"Description\"].apply(lambda x: clean_description(x))\n",
    "df[\"Description_Cleaned\"].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83d52982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing clean df\n",
    "df.to_csv(r\"D:\\DATA SCIENCE AND ML\\Project\\job_trend_predictor\\data\\processed\\cleaned\\cleaned_job_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
